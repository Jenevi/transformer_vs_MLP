# План на 2025-10-25

## Текущее состояние репозитория
- `README.md` описывает требования, порядок запуска обучения и настройку гиперпараметров.
- `tiny_transformer.py` реализует чтение корпуса, токенизацию, минимальный трансформер с обучением и генерацией текста.
- `tests/test_tiny_transformer.py` покрывает базовые проверки: чтение корпуса, токенизатор, прямой проход модели и длину генерации.
- `pyproject.toml` публикует только модуль трансформера; других пакетов пока нет.

## Реализовано
- Базовый символьный трансформерный языковой модельный пайплайн с CLI-параметрами и образцом генерации (`tiny_transformer.py`).
- MLP-бейзлайн с той же тренировочной и оценочной логикой, доступный через CLI (`tiny_transformer.py`).
- Минимальная документация по запуску и настройке гиперпараметров (`README.md`).
- Юнит-тесты для ключевых компонентов трансформера и MLP (`tests/test_tiny_transformer.py`).

## Осталось сделать
- Организовать управление датасетами, сохранение чекпоинтов и метрик для сопоставимых запусков.
- Актуализировать CLI и документацию для более глубокого выбора архитектуры, конфигурации оценок и автоматизации экспериментов.
- Дополнить тесты сценариями end-to-end и покрыть будущие модели, включая сравнение результатов.

## Ближайшие шаги
1. Доработать CLI и документацию: описать выбор архитектуры, параметры MLP и сценарии сравнения.
2. Добавить логирование метрик, сохранение результатов и дополнительные тесты для новых компонентов.
3. Организовать инфраструктуру датасетов и чекпоинтов для воспроизводимых экспериментов.
